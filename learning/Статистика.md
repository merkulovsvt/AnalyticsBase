# Введение

---

## Генеральная совокупность и выборка

### Генеральная совокупность

* **Генеральная совокупность** — совокупность всех объектов, над которыми производят наблюдение.
    * Пример — совершеннолетние жители города Москва.

### Выборка

* **Выборка** — часть отобранных из генеральной совокупности объектов.
    * Пример — 100 студентов МФТИ.

#### Виды выборок

* **Простая случайная выборка** (simple random sample) — случайным образом выбираем элементы генеральной совокупности.


* **Стратифицированная выборка** (stratified sample) — разделяем объекты по определенным признакам, затем из каждой
  страты отбираются участники пропорционально численности этой страты в популяции.


* **Групповая выборка** (cluster sample) — разделяем объекты на кластеры схожие между собой, выбираем некоторые из них и
  делаем простую случайную выборку из их элементов.

---

## Типы переменных

### Качественные переменные

* **Качественные переменные** (номинативные) — категории или группы, к которым можно отнести отдельные наблюдения.
    * Пример — марка автомобиля или пол человека.

### Ранговые переменные

* **Ранговые переменные** — это переменные, которые могут быть упорядочены, но не имеют фиксированного интервала между
  значениями.
    * Пример — места в марафонском забеге (мы можем сказать, что кто-то прибежал быстрее, но мы не знаем насколько)

### Количественные переменные

* **Количественные переменные** — данные, которые могут быть измерены и у которых есть числовое значение.
    * Пример — возраст человека.

#### Виды количественных переменных

* **Непрерывные** — переменная, которая может принимать любые значения в определенном диапазоне или на интервале.
    * Пример — доход человека.


* **Дискретные** — переменная, которая может принимать только целочисленные значения.
    * Пример — число детей в семье.

---

## Описательные статистики

### Меры центральной тенденции

* **Мера центральной тенденции** — число, служащее для описания множества значений одним-единственным числом.
    * Пример — вместо перечисления величин зарплат всех сотрудников организации говорят о средней зарплате.

#### Мода

* **Мода** (mode) — значение измеряемого признака, которое встречается максимально часто.

#### Медиана

* **Медиана** (median) — значение признака, которое делит упорядоченное множество данных пополам.
    * Обозначение — **med**.

#### Среднее арифметическое

* **Среднее арифметическое** (mean) — сумма всех значений измеренного признака, деленная на их количество.
    * Обозначение — **M** или **x̅**.

##### Свойства среднего

* **M<sub>X+C</sub>** = **M<sub>X</sub>** + C

* **M<sub>X*C</sub>** = **M<sub>X</sub>** * C

* ∑ (**x**<sub>i</sub> - **M<sub>X</sub>**) = 0

---

### Меры изменчивости

* **Мера изменчивости** — показатели, измеряющие вариацию (разброс) значений выборки.

#### Размах

* **Размах** (range) — разность максимального и минимального значения.
    * Обозначение — **R** = **X<sub>max</sub>** - **X<sub>min</sub>**.

#### Дисперсия

* **Дисперсия** (variance) — средний квадрат отклонений индивидуальных значений признака от средней величины.
    * Обозначение — **D** = ∑ (**x<sub>i</sub>** - **x̅**)<sup>2</sup> / **n**, где **n** — число элементов выборки.
        * Если дисперсия берётся от выборки, то в знаменателе **n-1** (см. **Степени свободы**).


* Квадрат необходим для того, чтобы дробь не занулилась (см. **Свойства среднего**).

##### Свойства дисперсии

* **D<sub>X+C</sub>** = **D<sub>X</sub>**

* **D<sub>X*C</sub>** = **D<sub>X</sub>** * C<sup>2</sup>

#### Среднеквадратичное отклонение

* **Среднеквадратичное отклонение** — квадратный корень дисперсии (√**D**.).
    * Для генеральной совокупности — **σ**.
    * Для выборки (стандартное отклонение) — **sd** (standard deviation).

##### Свойства среднеквадратичного отклонения

* **sd<sub>X+C</sub>** = **sd<sub>X</sub>**

* **sd<sub>X*C</sub>** = **sd<sub>X</sub>** * C

---

## Квартили распределения и график Box-plot

### Квартили распределения

* **Квартили распределения** — четверти упорядоченного множества данных.
    * Обозначение — **1-й**, **2-й**, **3-й**, **4-й** квартили.

### График Box-plot

* **Box-plot** (ящик с усами) — [ссылка](https://clck.ru/398X4i).

---

## Нормальное распределение и стандартизация

### Нормальное распределение

* **Нормальное распределение** — непрерывное симметричное распределение вероятностей с пиком в центре и симметричными
  боковыми сторонами.
    * Отклонения от среднего подчиняются определенному закону (**σ** - 34.1% наблюдений, **2σ** - 47.7% наблюдений, ...)

### Стандартизация

* **Стандартизация** (Z-преобразование) — преобразование полученных данных в стандартную **Z-шкалу** (Z-scores) со
  средним **M<sub>Z</sub>** = 0 и **D<sub>Z</sub>** = 1.
    * **M<sub>Z</sub>** = 0 (см. **Свойства среднего**) и **D<sub>Z</sub>** = 1 (см. **Свойства дисперсии**)
    * Формула — **z<sub>i</sub>** = (**x<sub>i</sub>** - **x̅**) / **σ<sub>x</sub>**
      (в знаменателе могут быть и **σ**, и **sd**, и **se**.)
    * [Таблица Z-значений](https://web.archive.org/web/20180729102938/http://users.stat.ufl.edu/~athienit/Tables/Ztable.pdf).

---

## Центральная предельная теорема

* **Центральная предельная теорема** — распределение выборочных средних значений приблизительно нормально, если размер
  выборки достаточно велик.

**Пояснение**:

1. Предположим исследуемый нами признак имеет нормальное распределение в генеральной совокупности с
   некоторым средним значением **M** и среднеквадратичным отклонением **σ**.

2. Мы многократно извлекаем выборки, равные **n** по объёму и в каждой из них высчитываем среднее значение и строим
   распределение этих выборочных средних.

3. Оно будет нормальным со средним значением равным **M** и стандартным отклонением равным <u>стандартной ошибке
   среднего</u> **se** = **σ** / √**n** (standard error).
    * Если **n** > 30, то достаточно извлечь всего лишь одну выборку и **se** = **sd<sub>x</sub>** / √**n**

---

## Доверительный интервал для среднего

* **Доверительный интервал для среднего** — это интервал выборки, который с заданной вероятностью (95% — **M** ±
  1.96**σ**, 99% — **M** ± 2.58**σ**, ...) включает среднее значение генеральной совокупности.
    * Пример — выборка с **x̅** = 100, **sd<sub>x</sub>** = 4, **n** = 64 => **se** = 0.5 => 95% — [91.02; 100.98]

---

## Идея статистического вывода, p-уровень значимости

### Идея статистического вывода

* **Идея статистического вывода** — принять (отвергнуть) гипотезы на основе данных (не оценивать неизвестный параметр
  генеральной совокупности).

### Пример с p-уровнем значимости

1. Пусть на выздоровление при некотором заболевании требуется в среднем **M** = 20 дней. Мы разработали новый препарат и
   хотим проверить, можно ли сократить этот срок.

2. Мы набрали выборку из **n** = 64 пациентов и опробовали на них новый способ лечения. Оказалось, что средний срок
   выздоровления сократился до **x̅** = 18.5 при стандартном отклонении **sd** = 4.

3. В нашем эксперименте между собой будут конкурировать 2 гипотезы.
    * **Гипотеза 0** — **M<sub>П</sub>** == 20.
    * **Гипотеза 1** — **M<sub>П</sub>** != 20.

4. Пусть верна **Гипотеза 0** => в соответствии с **ЦПТ** — **se** = 4 / 8 = 0.5.

5. Выполняем стандартизацию — z = (18.5 - 20) / 0.5 = -3 (отклонение на **3σ** влево).  
   **p-значение** = 2 * P(x<-3) = P(x<-3 OR x>3)

6. Если **p** > 0.05 (конкретное число зависит от ситуации), то подходит **Гипотеза 0**, иначе у нас достаточно
   оснований её отклонить и выбрать **Гипотеза 1**.


* Если верна **Гипотеза 0**, то вероятность получить такие или ещё выраженные различия равна **p-уровню значимости**.

* Чем меньше **p-уровень значимости**, тем больше оснований отклонить **Гипотезу 0**.

* **p-уровень значимости** ничего не говорит про:
    * то, с какой вероятностью верна **Гипотеза 0**,
    * правильность результат,
    * величину различия.

### Ошибки статистического вывода

* **Ошибка первого рода** — отклонили **Гипотезу 0**, хотя она была верна.


* **Ошибка второго рода** — приняли **Гипотезу 0**, хотя она была неверна.

---

# Сравнение средних

---

## t-распределение

* **[t-распределение](https://clck.ru/399PZL)** (распределение Стьюдента) — используется, когда число наблюдений **n**
  невелико (на самом деле неважно) и мы не знаем стандартное отклонение **σ** в генеральной совокупности.
    * Формула — **t<sub>i</sub>** = (**x<sub>i</sub>** - **x̅**) / (**sd<sub>x</sub>** / √**n**).
    * Число степеней свободы — **df** = **n** - 1 (degree of freedom). С увеличением числа **df** распределение
      стремится к нормальному.


* Всегда используем **t-распределение** для проверки гипотез, если нам неизвестно стандартное отклонение в генеральной
  совокупности, необходимое для расчета стандартной ошибки, даже если объем выборки больше 30.

### Пример

1. Предположим, что в генеральной совокупности среднее значение **M** = 10.

2. На нашей выборки мы получили среднее **x̅** = 10.8, стандартное отклонение **sd** = 2, **n** = 25.

3. Рассчитаем **z** = (10.8 - 10) / (2 / 5) = 2 => **p** = 0.0455 < 0.05.
    * [Калькулятор](https://gallery.shinyapps.io/dist_calc/).

4. Рассчитаем **t** = (10.8 - 10) / (2 / 5) = 2 и **df** = 24 => **p** = 0.056 > 0.05.
    * [Калькулятор](https://gallery.shinyapps.io/dist_calc/).

### Число степеней свободы

* **Число степеней свободы** — количество элементов, которые могут варьироваться при расчете некоторого статистического
  показателя.
    * Пример — Есть 10 наблюдений и мы знаем среднее значение по ним, то достаточно знать среднее и <u>9</u> из них,
      чтобы полностью знать, чему равен 10-й из них.

---

## Сравнение двух средних, t-критерий Стьюдента

### t-критерий Стьюдента

* **t-критерий Стьюдента** (парный t-тест) — критерий, который позволяет сравнить значимо ли различаются две выборки
  (два выборочных средних) между собой.


* [Калькулятор](https://vavilovva.shinyapps.io/dist_calc/).

* Желательно, чтобы дисперсий выборок были примерно одинаковы (гомогенность дисперсий).

* Если размер выборок **n** < 30, то очень важно наличие нормальности распределений наших двух выборок.

* [Таблица критических значений](https://www.medcalc.org/manual/t-distribution-table.php) для нахождения нужного
  **t-значения** (нужно, например, для нахождения границ доверительного интервала, тк 1.96 не подходит для
  t-распределения).

### Пример (теоретический)

* [Видео](https://stepik.org/lesson/9249/step/3?unit=1829)

1. **Первая выборка** — из пациентов, которые не принимали новое лекарство.  
   **Вторая выборка** — из пациентов, которые принимали новое лекарство.

2. Предположим, мы хотим сравнить два средних выборочных значения — **x̅<sub>1</sub>** (**sd<sub>1</sub>**, **n<sub>
   1</sub>**) и **x̅<sub>2</sub>** (**sd<sub>2</sub>**, **n<sub>2</sub>**).

3. В нашем эксперименте между собой будут конкурировать 2 гипотезы.
    * **Гипотеза 0** — лекарство не работает, выборки принадлежат одной **ГС**
      (**M<sub>1</sub>** == **M<sub>2</sub>**).
    * **Гипотеза 1** — лекарство работает, выборки принадлежат разным **ГС**
      (**M<sub>1</sub>** != **M<sub>2</sub>**).

4. Пусть верна **Гипотеза 0**, тогда при многократном повторении нашего эксперимента и расчете разностей между
   выборочными значениями, величина **x̅<sub>1</sub>** - **x̅<sub>2</sub>** распределилась бы **нормально**
   (**t-распределение**, тк мы не знаем **σ**) вокруг соответствующего значения генеральной совокупности (**M<sub>
   1</sub>** - **M<sub>2</sub>** = 0).

5. Стандартная ошибка этого распределения рассчитывается по формуле **se** = (**sd<sub>1</sub><sup>2</sup>** /
   **n1** + **sd<sub>2</sub><sup>2</sup>** / **n2**)**<sup>0.5</sup>**, а число степеней свободы **df** = **df<sub>
   1</sub>** + **df<sub>2</sub>** = **n<sub>1</sub>** + **n<sub>2</sub>** - 2.

6. Формула **t-критерия** (t-значения) — t = ((**x̅<sub>1</sub>** - **x̅<sub>2</sub>**) - (**M<sub>1</sub>** - **M<sub>
   2</sub>**)) / (**sd<sub>1</sub><sup>2</sup>** / **n1** + **sd<sub>2</sub><sup>2</sup>** / **n2**)**<sup>0.5</sup>**.

7. Рассчитаем **p**, зная, чему равняются **t** и **df**.

### Пример (практический)

* [Видео](https://stepik.org/lesson/9249/step/5?unit=1829)

1. **Первая выборка** — **x̅<sub>1</sub>** = 89.9, **sd<sub>1</sub>** = 11.3, **n<sub>1</sub>** = 20.  
   **Вторая выборка** — **x̅<sub>2</sub>** = 80.7, **sd<sub>2</sub>** = 11.7, **n<sub>2</sub>** = 20.

2. В нашем эксперименте между собой будут конкурировать 2 гипотезы.
    * **Гипотеза 0** — средняя температура плавления ДНК первого вида такая же, как и у ДНК второго вида.
      (**M<sub>1</sub>** == **M<sub>2</sub>**).
    * **Гипотеза 1** — средняя температура плавления ДНК первого вида не такая, как у ДНК второго вида.
      (**M<sub>1</sub>** != **M<sub>2</sub>**).

3. Применим формулу **t** = ((89.9 - 80.7) - 0) / (3.63) = 2.5, те <u>наша разность отклонилась от исходного значения на
   **2.5σ** вправо</u>. **df** = 38.

4. Рассчитаем **p**, зная, что **t** = 2.5 и **df** = 38. **p** = 0.0167 < 0.05 => у нас достаточно оснований отклонить
   **Гипотезу 0**.


* Полезная [задача](https://stepik.org/lesson/9249/step/13?discussion=6715430&unit=1829) с объяснением.

---

## Проверка распределения на нормальность, QQ-Plot

### QQ-Plot

* **[QQ-Plot](https://stepik.org/lesson/8082/step/4)** (Quantile–Quantile Plot) — показывает, насколько
  выборочные значения соответствуют предсказанным (идеальному нормальному распределению).

* Полезное для понимания [видео](https://www.youtube.com/watch?v=X9_ISJ0YpGw).

### Тест Шапиро-Вилка

* **Тест Шапиро-Вилка** — используется для определения того, соответствует ли выборка нормальному распределению.
    * Если p > 0.05 оснований отклонять гипотезу, что выборка распределена нормально отсутствует.

### Проблема выбросов

* **Выброс** — экстремально высокое или экстремально низкое значение выборки.
    * Они могут испортить p-уровень значимости.

### U-критерий Манна-Уитни

* **U-критерий Манна-Уитни** — проверяет гипотезу о том, что две генеральные совокупности, из которых были отобраны
  выборки, эквивалентны по расположению.

---

## Однофакторный дисперсионный анализ, F-значение.

* **Однофакторный дисперсионный анализ** (One-way ANOVA) — применяется для сравнения нескольких групп между собой в
  экспериментах и исследованиях.


* **Независимая переменная** — переменная, которая будет разделять наших испытуемых или наблюдения на группы
  (номинативная переменная с нескольким градациями).

* **Зависимая переменная** — количественная переменная, по степени выраженности которой мы сравниваем группы.

### Расчет на практическом примере

1. Нам даны 3 группы с некоторыми значениями:
    * **1 группа** — 3, 1, 2.
    * **2 группа** — 5, 3, 4.
    * **3 группа** — 7, 6, 5.

2. В нашем эксперименте между собой будут конкурировать 2 гипотезы.
    * **Гипотеза 0** — **M<sub>1</sub>** == **M<sub>2</sub>** == **M<sub>3</sub>**.
    * **Гипотеза 1** — Хотя бы пара средних значимо различаются между собой.

3. Высчитываем среднее значение всех наблюдений **x̅̅** = (3+1+2+5+3+4+7+6+5)/9 = 4.

4. Высчитываем общую сумму квадратов отклонений от среднего (значение общей изменчивости данных)
   **SST** = (3-4)<sup>2</sup> + (1-4)<sup>2</sup> + ... = 30 (sum of squares total).

5. Высчитаем число степеней свободы **df** = 9 - 1 = 8.

* **SST** проистекает только из 2 источников:
    1. **SSB** (sum of squares between groups) — значение межгрупповой изменчивости данных.
    2. **SSW** (sum of squares within groups) — значение внутригрупповой изменчивости данных.

6. Высчитаем **SSB**. **x̅<sub>1</sub>** = 2, **x̅<sub>2</sub>** = 4, **x̅<sub>3</sub>** = 6, **x̅̅** = 4.  
   Получаем **SSB** = 3 * (2-4)<sup>2</sup> + 3 * (4-4)<sup>2</sup> + 3 * (6-4)<sup>2</sup> = 24.  
   **df<sub>SSB</sub>** = **m** - 1 = 3 - 1 = 2, где **m** - общее число групп.

7. Высчитаем **SSW**. **x̅<sub>1</sub>** = 2, **x̅<sub>2</sub>** = 4, **x̅<sub>3</sub>** = 6.  
   Получаем **SSW** = (3-2)<sup>2</sup> + ... + (5-4)<sup>2</sup> + ... + (7-6)<sup>2</sup> + ... = 6.  
   **df<sub>SSW</sub>** = **N** - **m** = 9 - 3 = 6, где **N** - общее число элементов, а **m** - общее число групп.

8. Выходит, что **SST** = 30, **SSB** = 24, **SSW** = 6 (**SST** = **SSB** + **SSW**).
    * Если **SSB** > **SSW**, то сами группы значительно различаются между собой.
    * Если **SSB** < **SSW**, то значения групп значительно различаются между собой.


* **Межгрупповой средний квадрат** — **MS<sub>bg</sub>** = **SSB** / **df<sub>SSB</sub>**.

* **Внутригрупповой средний квадрат** — **MS<sub>wg</sub>** = **SSW** / **df<sub>SSW</sub>**.


* **F-значение** — основной статистический показатель дисперсионного показателя.
    * **F** = **MS<sub>bg</sub>** / **MS<sub>wg</sub>**.

9. Рассчитаем **F-значение**. **F** = 12 / 1 = 12.

10. Найдём **p** = 0.008 => отвергаем **Гипотезу 0**.
    * [Калькулятор](https://vavilovva.shinyapps.io/dist_calc/).

---

## Множественные сравнения в ANOVA

* **Множественные сравнения в ANOVA** — попарное сравнение всех групп между собой.

### Проблема множественного сравнения выборок

* Чем больше групп, которые можно сравнивать между собой, тем больше шанс получить хотя бы одно значимое различие между
  ними.

### Поправка Бонферрони

* Если вероятность ошибки первого рода возрастает пропорционально количеству групп (гипотез),
  которые мы сравниваем между собой, то показатель **α** (по умолчанию 0.05) необходимо корректировать.


* **Поправка Бонферрони** — если мы хотим удержать вероятность ошибки первого рода на уровне 0.05, то мы должны
  разделить показатель **α** на количество парных сравнений, которые мы произведём в нашем эксперименте.


* Критикуется, так как мы через понижение **p-уровня** значимости упускаем какой-то большой процент значимых
  результатов.

### Критерий Тьюки

**Критерий Тьюки** —

## Многофакторный дисперсионный анализ

### Двухфакторный дисперсионный анализ

### Взаимодействие факторов в ANOVA

### Требования к данным

### Интерпрертация результатов

---

# Корреляция и регрессия

---

## Понятие корреляции

### 